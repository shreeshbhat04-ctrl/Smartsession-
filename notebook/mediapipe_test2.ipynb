{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba940506-a978-4ba5-873c-65cc91873077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my notebook was corrupted so had add this line\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "#same imports\n",
    "#vision\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "#math and time stuff for detection\n",
    "import math\n",
    "from time import time as now\n",
    "import time as time_module\n",
    "from collections import deque\n",
    "# visualization\n",
    "from PIL import Image\n",
    "from IPython.display import display, clear_output\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cbd9430-9d7d-4a9a-a922-4bc191f6d75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unchanged\n",
    "def euclid(p1, p2):\n",
    "    return math.hypot(p1.x - p2.x, p1.y - p2.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fba7a8cb-d163-413c-8f88-c075e984ff78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "clf = joblib.load(\"models/confusion_tree.joblib\")\n",
    "print(\"Model loaded:\", type(clf))# we take our trained classifer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f52580bb-01e5-4af5-a807-4863cd9ad028",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_options = python.BaseOptions(\n",
    "    model_asset_path=\"face_landmarker.task\"   # changed because MediaPipe wasn't compatible with Python 3.10\n",
    ")\n",
    "\n",
    "options = vision.FaceLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    running_mode=vision.RunningMode.VIDEO,\n",
    "    num_faces=1,\n",
    "    output_face_blendshapes=False\n",
    ")\n",
    "\n",
    "detector = vision.FaceLandmarker.create_from_options(options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0857a9f3-715a-46ed-9b0b-ee82d1c06d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#took it from stack overflow\n",
    "# Gaze & Eye Landmarks (refined landmarks require refine_landmarks=True)\n",
    "right_iris_center = 474     # Right iris/pupil center\n",
    "left_iris_center = 468      # Left iris/pupil center  \n",
    "right_eye_inner = 263       # Right eye inner corner (near nose)\n",
    "left_eye_inner = 362        # Left eye inner corner (near nose)\n",
    "right_eye_outer = 133       # Right eye outer corner\n",
    "left_eye_outer = 33        # Left eye outer corner \n",
    "# Brow Landmarks\n",
    "left_brow_inner = 107       # Left eyebrow inner point  \n",
    "right_brow_inner = 336      # Right eyebrow inner point\n",
    "# Face Contour\n",
    "left_face_contour = 234     # Left jaw/cheek extreme\n",
    "right_face_contour = 454    # Right jaw/cheek extreme\n",
    "# Mouth Landmarks\n",
    "upper_left_lip_corner = 61  # Upper outer lip left corner\n",
    "lower_right_lip_corner = 291 # Lower outer lip right corner (code pairs with 61)\n",
    "upper_inner_lip_center = 13 # Top inner lip center\n",
    "lower_inner_lip_center = 14 # Bottom inner lip center\n",
    "# Nose\n",
    "nose_tip = 1                # Nose tip (smile reference)\n",
    "#extraction of these features\n",
    "def browratio(lm):\n",
    "     return euclid(lm[left_brow_inner], lm[right_brow_inner]) / euclid(lm[left_face_contour], lm[right_face_contour])\n",
    "def mouthfeature(lm):\n",
    "    left, right = lm[upper_left_lip_corner], lm[lower_right_lip_corner]\n",
    "    top, bottom = lm[upper_inner_lip_center], lm[lower_inner_lip_center]\n",
    "    nose = lm[nose_tip]\n",
    "    facewidth = euclid(lm[left_face_contour], lm[right_face_contour])\n",
    "    mouth_w = euclid(left, right) / facewidth\n",
    "    mouth_open = euclid(top, bottom) / facewidth\n",
    "    smile_up = (nose.y - (left.y + right.y) / 2) / facewidth\n",
    "    return mouth_w, mouth_open, smile_up\n",
    "def headroll(lm):\n",
    "    L, R = lm[left_face_contour], lm[right_face_contour]\n",
    "    return math.degrees(math.atan2(R.y - L.y, R.x - L.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87bda4d9-6e3a-494e-8d4a-bc225f385190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brow_confusion_rule(landmarks):\n",
    "    brow_l = landmarks[left_brow_inner]\n",
    "    brow_r = landmarks[right_brow_inner]\n",
    "    face_l = landmarks[left_face_contour]\n",
    "    face_r = landmarks[right_face_contour]\n",
    "    facewidth = euclid(face_l, face_r)\n",
    "    if facewidth == 0:\n",
    "        return False, 0.0\n",
    "    brow_dist = euclid(brow_l, brow_r)\n",
    "    ratio = brow_dist / facewidth\n",
    "    Brow_confusion = 0.1  # adjust this value as needed\n",
    "    return ratio < Brow_confusion, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd6a90e6-da48-42fc-9d94-5200ce0cf01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same features from media test1 with added gaze up down etc\n",
    "def is_happy(self, lm):\n",
    "    # mouth corners and opening\n",
    "    left = lm[upper_left_lip_corner ]\n",
    "    right = lm[lower_right_lip_corner]\n",
    "    top = lm[upper_inner_lip_center]\n",
    "    bottom = lm[lower_inner_lip_center]\n",
    "    face_l = lm[left_face_contour]\n",
    "    face_r = lm[right_face_contour]\n",
    "    facewidth = euclid(face_l, face_r)\n",
    "    if facewidth == 0:\n",
    "        return False\n",
    "    mouthwidth = euclid(left, right) / facewidth\n",
    "    mouthopen = euclid(top, bottom) / facewidth\n",
    "    smileup = ((left.y + right.y) / 2 - lm[nose_tip].y) / facewidth\n",
    "    return (\n",
    "        mouthwidth > 0.33 and\n",
    "        mouthopen > 0.02 and\n",
    "        smileup < -0.01\n",
    "    )\n",
    "def get_vertical_gaze(self, lm):\n",
    "    iris = lm[right_iris_center]\n",
    "    upper = lm[386]\n",
    "    lower = lm[374]\n",
    "    eye_height = euclid(upper, lower)\n",
    "    if eye_height == 0:\n",
    "        return \"CENTER\"\n",
    "    ratio = euclid(iris, upper) / eye_height\n",
    "    if ratio > 0.35:\n",
    "        return \"UP\"\n",
    "    elif ratio < 0.65:\n",
    "        return \"DOWN\"\n",
    "    return \"CENTER\"\n",
    "def get_gaze(self, landmarks):\n",
    "    # ---- Horizontal ----\n",
    "    iris = landmarks[474]\n",
    "    inner = landmarks[263]\n",
    "    outer = landmarks[362]\n",
    "    eye_width = euclid(inner, outer)\n",
    "    gaze_h = \"CENTER\"\n",
    "    if eye_width != 0:\n",
    "        ratio_h = euclid(iris, inner) / eye_width\n",
    "        if ratio_h < 0.2:\n",
    "            gaze_h = \"RIGHT\"\n",
    "        elif ratio_h > 0.8:\n",
    "            gaze_h = \"LEFT\"\n",
    "    #  Vertical \n",
    "    gaze_v = self.get_vertical_gaze(landmarks)\n",
    "\n",
    "    # ---- Merge ----# right to left\n",
    "    if gaze_h != \"CENTER\":\n",
    "        return gaze_h\n",
    "    if gaze_v != \"CENTER\":# up to down\n",
    "        return gaze_v\n",
    "\n",
    "    return \"CENTER\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90f7fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class StudentIntegrityMonitor:\n",
    "    \"\"\"\n",
    "    Complete monitoring system for student integrity detection.\n",
    "    Tracks: Gaze direction, Confusion (ML + rule-based), Happiness, Looking away\n",
    "    \"\"\"\n",
    "    def __init__(self, detector, clf, gaze_limit=4.5):\n",
    "        self.detector = detector\n",
    "        self.clf = clf\n",
    "        self.gaze_limit = gaze_limit  # seconds before flagging \"looking away\"\n",
    "        self.look_away_st = None  # timestamp when looking away started\n",
    "        self.pred_buffer = deque(maxlen=7)  # smoothing buffer for ML predictions\n",
    "        self.frame_count = 0\n",
    "        self.last_timestamp_ms = 0  # Track last timestamp for monotonicity\n",
    "    \n",
    "    # ---- FEATURE EXTRACTION METHODS ----\n",
    "    def browratio(self, lm):\n",
    "        \"\"\"Calculate brow width relative to face width\"\"\"\n",
    "        return euclid(lm[left_brow_inner], lm[right_brow_inner]) / euclid(lm[left_face_contour], lm[right_face_contour])\n",
    "    \n",
    "    def mouthfeature(self, lm):\n",
    "        \"\"\"Extract mouth width, opening, and smile angle\"\"\"\n",
    "        left, right = lm[upper_left_lip_corner], lm[lower_right_lip_corner]\n",
    "        top, bottom = lm[upper_inner_lip_center], lm[lower_inner_lip_center]\n",
    "        nose = lm[nose_tip]\n",
    "        facewidth = euclid(lm[left_face_contour], lm[right_face_contour])\n",
    "        mouth_w = euclid(left, right) / facewidth\n",
    "        mouth_open = euclid(top, bottom) / facewidth\n",
    "        smile_up = (nose.y - (left.y + right.y) / 2) / facewidth\n",
    "        return mouth_w, mouth_open, smile_up\n",
    "    \n",
    "    def headroll(self, lm):\n",
    "        \"\"\"Calculate head roll angle from face contour\"\"\"\n",
    "        L, R = lm[left_face_contour], lm[right_face_contour]\n",
    "        return math.degrees(math.atan2(R.y - L.y, R.x - L.x))\n",
    "    \n",
    "    # ---- DETECTION METHODS ----\n",
    "    def is_happy(self, lm):\n",
    "        \"\"\"Detect if student is happy/excited based on mouth features\"\"\"\n",
    "        left = lm[upper_left_lip_corner]\n",
    "        right = lm[lower_right_lip_corner]\n",
    "        top = lm[upper_inner_lip_center]\n",
    "        bottom = lm[lower_inner_lip_center]\n",
    "        face_l = lm[left_face_contour]\n",
    "        face_r = lm[right_face_contour]\n",
    "        facewidth = euclid(face_l, face_r)\n",
    "        if facewidth == 0:\n",
    "            return False\n",
    "        mouthwidth = euclid(left, right) / facewidth\n",
    "        mouthopen = euclid(top, bottom) / facewidth\n",
    "        smileup = ((left.y + right.y) / 2 - lm[nose_tip].y) / facewidth\n",
    "        return (\n",
    "        (mouthwidth > 0.33 and\n",
    "            mouthopen > 0.02) or\n",
    "            smileup < -0.3\n",
    "        )\n",
    "    \n",
    "    def get_vertical_gaze(self, lm):\n",
    "        \"\"\"Detect vertical gaze direction (UP, CENTER, DOWN)\"\"\"\n",
    "        iris = lm[right_iris_center]\n",
    "        upper = lm[386]\n",
    "        lower = lm[374]\n",
    "        eye_height = euclid(upper, lower)\n",
    "        if eye_height == 0:\n",
    "            return \"CENTER\"\n",
    "        ratio = euclid(iris, upper) / eye_height\n",
    "        # Small ratio = iris close to upper eyelid = looking UP\n",
    "        # Large ratio = iris far from upper eyelid = looking DOWN\n",
    "        if ratio < 0.35:\n",
    "            return \"UP\"\n",
    "        elif ratio > 0.65:\n",
    "            return \"DOWN\"\n",
    "        return \"CENTER\"\n",
    "    \n",
    "    def get_gaze(self, landmarks):\n",
    "        \"\"\"Detect horizontal and vertical gaze direction\"\"\"\n",
    "        # ---- Horizontal ----\n",
    "        iris = landmarks[474]\n",
    "        inner = landmarks[263]\n",
    "        outer = landmarks[362]\n",
    "        eye_width = euclid(inner, outer)\n",
    "        gaze_h = \"CENTER\"\n",
    "        if eye_width != 0:\n",
    "            ratio_h = euclid(iris, inner) / eye_width\n",
    "            if ratio_h < 0.2:\n",
    "                gaze_h = \"RIGHT\"\n",
    "            elif ratio_h > 0.8:\n",
    "                gaze_h = \"LEFT\"\n",
    "        # ---- Vertical ----\n",
    "        gaze_v = self.get_vertical_gaze(landmarks)\n",
    "        \n",
    "        # ---- Merge ----\n",
    "        if gaze_h != \"CENTER\":\n",
    "            return gaze_h\n",
    "        if gaze_v != \"CENTER\":\n",
    "            return gaze_v\n",
    "        return \"CENTER\"\n",
    "    \n",
    "    def brow_confusion_rule(self, landmarks):\n",
    "        \"\"\"Rule-based confusion detection using brow position\"\"\"\n",
    "        brow_l = landmarks[left_brow_inner]\n",
    "        brow_r = landmarks[right_brow_inner]\n",
    "        face_l = landmarks[left_face_contour]\n",
    "        face_r = landmarks[right_face_contour]\n",
    "        facewidth = euclid(face_l, face_r)\n",
    "        if facewidth == 0:\n",
    "            return False, 0.0\n",
    "        brow_dist = euclid(brow_l, brow_r)\n",
    "        ratio = brow_dist / facewidth\n",
    "        Brow_confusion = 0.1  # threshold\n",
    "        return ratio < Brow_confusion, ratio\n",
    "    \n",
    "    def predict(self, lm):\n",
    "        \"\"\"ML prediction for confusion\"\"\"\n",
    "        brow = self.browratio(lm)\n",
    "        mouth_w, mouth_open, smile_up = self.mouthfeature(lm)\n",
    "        head_roll_abs = abs(self.headroll(lm))\n",
    "        X = pd.DataFrame(\n",
    "            [[brow, mouth_w, mouth_open, smile_up, head_roll_abs]],\n",
    "            columns=self.clf.feature_names_in_\n",
    "        )\n",
    "        pred = self.clf.predict(X)[0]  # 1=>confused, 0=>not confused\n",
    "        return pred, {\n",
    "            \"brow\": brow,\n",
    "            \"smile_up\": smile_up,\n",
    "            \"roll\": head_roll_abs\n",
    "        }\n",
    "    \n",
    "    def smooth_prediction(self, pred):\n",
    "        \"\"\"Smooth ML predictions using majority voting over 7 frames\"\"\"\n",
    "        self.pred_buffer.append(pred)\n",
    "        return sum(self.pred_buffer) >= (len(self.pred_buffer) // 2 + 1)\n",
    "    \n",
    "    # ---- MAIN PIPELINE ----\n",
    "    def process(self, frame):\n",
    "        \"\"\"\n",
    "        Complete analysis pipeline:\n",
    "        1. Extract face landmarks\n",
    "        2. Check gaze direction & timeout\n",
    "        3. Check confusion (ML + rule-based)\n",
    "        4. Check happy state\n",
    "        5. Return final status with features\n",
    "        \"\"\"\n",
    "        self.frame_count += 1\n",
    "        # Use actual time-based timestamp to ensure monotonicity\n",
    "        current_time_ms = int(time_module.time() * 1000)\n",
    "        # Ensure timestamp is always strictly increasing\n",
    "        if current_time_ms <= self.last_timestamp_ms:\n",
    "            timestamp_ms = self.last_timestamp_ms + 1\n",
    "        else:\n",
    "            timestamp_ms = current_time_ms\n",
    "        self.last_timestamp_ms = timestamp_ms\n",
    "        \n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        mp_image = mp.Image(\n",
    "            image_format=mp.ImageFormat.SRGB,\n",
    "            data=rgb\n",
    "        )\n",
    "        result = self.detector.detect_for_video(mp_image, timestamp_ms)\n",
    "        \n",
    "        gaze = \"CENTER\"\n",
    "        feats = {}\n",
    "        \n",
    "        # ---- INTEGRITY CHECKS ----\n",
    "        if not result.face_landmarks:\n",
    "            return \"No Face\", \"No Face\", gaze, feats\n",
    "        if len(result.face_landmarks) > 1:\n",
    "            return \"Multiple Faces\", \"Alert\", gaze, feats\n",
    "        \n",
    "        landmarks = result.face_landmarks[0]\n",
    "        \n",
    "        # ---- GAZE (INTEGRITY + TIME-BASED) ----\n",
    "        gaze = self.get_gaze(landmarks)\n",
    "        if gaze != \"CENTER\":\n",
    "            if self.look_away_st is None:\n",
    "                self.look_away_st = now()\n",
    "            elif now() - self.look_away_st > self.gaze_limit:\n",
    "                return \"Looking Away\", \"Alert\", gaze, feats\n",
    "        else:\n",
    "            self.look_away_st = None\n",
    "        \n",
    "        # ---- CONFUSION (ML FIRST + SMOOTHING) ----\n",
    "        pred, feats = self.predict(landmarks)\n",
    "        confused = self.smooth_prediction(pred)\n",
    "        if confused:\n",
    "            return \"Confused\", \"Confused\", gaze, feats\n",
    "        \n",
    "        # ---- CONFUSION FALLBACK (RULE-BASED SAFETY NET) ----\n",
    "        rule_confused, ratio = self.brow_confusion_rule(landmarks)\n",
    "        if rule_confused:\n",
    "            return \"Confused\", \"Confused\", gaze, feats\n",
    "        \n",
    "        # ---- HAPPY (RULE-BASED OVERRIDE) ----\n",
    "        if self.is_happy(landmarks):\n",
    "            return \"Happy\", \"Happy\", gaze, feats\n",
    "        \n",
    "        # ---- DEFAULT ----\n",
    "        return \"Focused\", \"Focused\", gaze, feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "806ce7c1-abd3-47e2-bc5c-e0b27734c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(self, frame):\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    mp_image = mp.Image(\n",
    "        image_format=mp.ImageFormat.SRGB,\n",
    "        data=rgb\n",
    "    )\n",
    "    result = self.detector.detect(mp_image)\n",
    "    # same Thing\n",
    "    status = \"No Face\"\n",
    "    state = \"Neutral\"\n",
    "    gaze = \"Center\"\n",
    "    #  INTEGRITY CHECKS \n",
    "    if not result.face_landmarks:\n",
    "        return \"No Face\", \"No Face\", gaze, {}\n",
    "    if len(result.face_landmarks) > 1:\n",
    "        return \"Multiple Faces\", \"Alert\", gaze, {}\n",
    "    landmarks = result.face_landmarks[0]\n",
    "    #  GAZE (INTEGRITY, TIME-BASED) \n",
    "    gaze = self.get_gaze(landmarks)\n",
    "    if gaze != \"Center\":\n",
    "        if self.look_away_st is None:\n",
    "            self.look_away_st = now()\n",
    "        elif now() - self.look_away_st > self.gaze_limit:\n",
    "            return \"Looking Away\", \"Alert\", gaze, {}\n",
    "    else:\n",
    "        self.look_away_st = None\n",
    "    #  CONFUSION (ML FIRST) \n",
    "    pred, feats = predict(landmarks)\n",
    "    if pred == 1:\n",
    "        return \"Confused\", \"Confused\", gaze, feats\n",
    "\n",
    "    # ---- CONFUSION FALLBACK (RULE-BASED SAFETY NET) ----\n",
    "    rule_confused, ratio = brow_confusion_rule(landmarks)\n",
    "    if rule_confused:\n",
    "        return \"Confused\", \"Confused\", gaze, feats\n",
    "    #  HAPPY (RULE-BASED OVERRIDE) \n",
    "    if self.is_happy(landmarks):\n",
    "        return \"Happy\", \"Happy\", gaze, feats\n",
    "    #  DEFAULT \n",
    "    return \"Focused\", \"Focused\", gaze, feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "878333e2-6358-45d0-bc60-9ec0d6d9142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(lm):\n",
    "    brow = browratio(lm)\n",
    "    mouth_w, mouth_open, smile_up = mouthfeature(lm)\n",
    "    head_roll_abs = abs(headroll(lm))\n",
    "    X = pd.DataFrame(\n",
    "        [[brow, mouth_w, mouth_open, smile_up, head_roll_abs]],\n",
    "        columns=clf.feature_names_in_\n",
    "    )\n",
    "    pred = clf.predict(X)[0]  # 1 => confused, 0 => nope\n",
    "    return pred, {\n",
    "        \"brow\": brow,\n",
    "        \"smile\": smile_up,\n",
    "        \"roll\": head_roll_abs\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d447ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def predict(lm):\n",
    "    brow = browratio(lm)\n",
    "    mouth_w, mouth_open, smile_up = mouthfeature(lm)\n",
    "    head_roll_abs = abs(headroll(lm))\n",
    "    X = pd.DataFrame(\n",
    "        [[brow, mouth_w, mouth_open, smile_up, head_roll_abs]],\n",
    "        columns=clf.feature_names_in_\n",
    "    )\n",
    "    pred = clf.predict(X)[0]  # 1=>confused, 0=>nope\n",
    "    return pred, {\n",
    "        \"brow\": brow,\n",
    "        \"smile_up\": smile_up,\n",
    "        \"roll\": head_roll_abs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac2fc877-35f8-4709-8f4f-d343bf80dfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_buffer = deque(maxlen=7)\n",
    "def smooth_prediction(pred):\n",
    "    pred_buffer.append(pred)\n",
    "    return sum(pred_buffer) >= (len(pred_buffer)//2 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bc8fc70-8077-47fc-9df1-eea789583fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting live verification. Press Q to quit.\n",
      "\n",
      "Detecting: Focused, Confused, Happy, Looking Away, No Face, Multiple Faces\n",
      "\n",
      "Monitoring stopped.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Instantiate the monitor with your detector and model\n",
    "monitor = StudentIntegrityMonitor(\n",
    "    detector=detector,\n",
    "    clf=clf,\n",
    "    gaze_limit=4.5  # Flag \"looking away\" after 3 seconds\n",
    ")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(\"Starting live verification. Press Q to quit.\")\n",
    "print(\"\\nDetecting: Focused, Confused, Happy, Looking Away, No Face, Multiple Faces\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run complete pipeline\n",
    "    status, state, gaze, feats = monitor.process(frame)\n",
    "    \n",
    "    # Color mapping\n",
    "    color_map = {\n",
    "        \"Focused\": (255, 255, 0),      # Yellow\n",
    "        \"Confused\": (0, 0, 255),       # Red\n",
    "        \"Happy\": (0, 255, 0),          # Green\n",
    "        \"Looking Away\": (0, 165, 255), # Orange\n",
    "        \"No Face\": (128, 128, 128),    # Gray\n",
    "        \"Multiple Faces\": (0, 255, 255) # Cyan\n",
    "    }\n",
    "    color = color_map.get(status, (128, 128, 128))\n",
    "    \n",
    "    # Display status and gaze\n",
    "    cv2.putText(frame, status, (20, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)\n",
    "    cv2.putText(frame, f\"Gaze: {gaze}\", (20, 80),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (200, 200, 200), 2)\n",
    "    \n",
    "    # Display extracted features\n",
    "    y_offset = 120\n",
    "    if feats:\n",
    "        cv2.putText(frame, f\"Brow: {feats.get('brow', 0):.3f}\", (20, y_offset),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 200, 0), 2)\n",
    "        cv2.putText(frame, f\"Smile: {feats.get('smile_up', 0):.3f}\", (20, y_offset + 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 200, 0), 2)\n",
    "        cv2.putText(frame, f\"Roll: {feats.get('roll', 0):.3f}\", (20, y_offset + 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 200, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Student Integrity Monitor\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"\\nMonitoring stopped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c61e20c-428e-4e2c-9940-2254e912124c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['brow_ratio', 'smile_up', 'mouth_open', 'mouth_width',\n",
       "       'head_roll_abs'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_names_in_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa4e058-4eda-48ba-8ba1-cbc3297fab3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (vision)",
   "language": "python",
   "name": "vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
